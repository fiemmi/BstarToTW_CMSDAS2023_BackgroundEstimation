{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "th_rsgluon = np.array([275.9*1.3, 62.41*1.3, 20.05*1.3, 7.92*1.3, 3.519*1.3, 0.9528*1.3, 0.3136*1.3, 0.1289*1.3, 0.0545*1.3, 0.02807*1.3, 0.01603*1.3, 0.009095*1.3, 0.005551*1.3, 0.003816*1.3])\n",
    "x_rsgluon  = np.array([0.5,0.75,1,1.25,1.5,2,2.5,3,3.5,4,4.5,5,5.5,6])\n",
    "\n",
    "th_zprime1 = np.array([5.83131e+01, 1.36051e+01, 4.50540e+00, 1.80866e+00, 8.13716e-01, 3.97420e-01, 2.05510e-01, 1.10890e-01, 6.17038e-02, 3.52336e-02, 2.05665e-02, 1.21935e-02, 7.34662e-03, 4.46826e-03, 2.75870e-03, 1.72335e-03, 1.09115e-03, 6.99838e-04, 4.58135e-04, 3.04742e-04, 2.07506e-04, 1.44911e-04, 1.03407e-04, 7.60116e-05, 5.71530e-05, 4.42244e-05, 3.49246e-05])\n",
    "x_zprime1  = np.array([0.5,0.75,1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7])\n",
    "\n",
    "\n",
    "th_zprime10 = np.array([5.36522e+02, 1.31954e+02, 4.48526e+01, 1.83735e+01, 8.47610e+00, 4.24656e+00, 2.26215e+00, 1.26395e+00, 7.34314e-01, 4.41032e-01, 2.72788e-01, 1.73249e-01, 1.12874e-01, 7.53710e-02, 5.15542e-02, 3.61230e-02, 2.59114e-02, 1.90265e-02, 1.42839e-02, 1.09496e-02, 8.55804e-03, 6.80722e-03, 5.50276e-03, 4.50943e-03, 3.74190e-03, 3.13889e-03, 2.65864e-03])\n",
    "x_zprime10  = np.array([0.5,0.75,1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7])\n",
    "\n",
    "th_zprime30 = np.array([1.32811e+03, 3.61926e+02, 1.29361e+02, 5.52047e+01, 2.65207e+01, 1.38696e+01, 7.74166e+00, 4.55142e+00, 2.79430e+00, 1.78062e+00, 1.17252e+00, 7.95149e-01, 5.53916e-01, 3.95485e-01, 2.88839e-01, 2.15406e-01, 1.63747e-01, 1.26704e-01, 9.95997e-02, 7.94496e-02, 6.42139e-02, 5.25241e-02, 4.34250e-02, 3.62486e-02, 3.05223e-02, 2.59064e-02, 2.21476e-02])\n",
    "x_zprime30  = np.array([0.5,0.75,1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.25,4.5,4.75,5,5.25,5.5,5.75,6,6.25,6.5,6.75,7])\n",
    "\n",
    "th_zprimeDM = np.array([-1, -1, -1, -1, -1, -1, -1, -1, -1]) \n",
    "x_zprimeDM  = np.array([1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5, 1.0)\n",
      "(0.75, 1.0)\n",
      "(1.0, 1.0)\n",
      "1.0 4.5054\n",
      "(1.25, 1.2)\n",
      "(1.5, 1.2)\n",
      "(1.75, 1.2)\n",
      "(2.0, 1.2)\n",
      "(2.25, 1.2)\n",
      "(2.5, 1.2)\n",
      "(2.75, 1.2)\n",
      "(3.0, 1.2)\n",
      "(3.25, 1.2)\n",
      "(3.5, 1.2)\n",
      "(3.75, 1.2)\n",
      "(4.0, 1.2)\n",
      "(4.25, 1.2)\n",
      "(4.5, 1.2)\n",
      "(4.75, 1.2)\n",
      "(5.0, 1.2)\n",
      "(5.25, 1.2)\n",
      "(5.5, 1.2)\n",
      "(5.75, 1.2)\n",
      "(6.0, 1.2)\n",
      "(6.25, 1.2)\n",
      "(6.5, 1.2)\n",
      "(6.75, 1.2)\n",
      "(7.0, 1.2)\n"
     ]
    }
   ],
   "source": [
    "have = [1.0, \n",
    "            1.2,\n",
    "            1.4,\n",
    "            1.6,\n",
    "            1.8,\n",
    "            2.0,\n",
    "            2.5, \n",
    "            3.0, \n",
    "            3.5, \n",
    "            4.0, \n",
    "            4.5]\n",
    "\n",
    "k = 0\n",
    "for i in range(len(x_zprime1)):\n",
    "    print(x_zprime1[i], have[k])\n",
    "    if x_zprime1[i] == have[k]:\n",
    "        k = k+1\n",
    "        print x_zprime1[i], th_zprime1[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "th_rsgluon = list( 1.3 * np.array([20.05, 3.519, 0.9528, 0.3136, 0.1289, 0.0545, 0.02807, 0.01603, 0.009095] ) )\n",
    "x_rsgluon   = [1,1.5,2,2.5,3,3.5,4,4.5,5]\n",
    "\n",
    "th_zprime1  = [4.50540e+00, 2.05510e-01, 2.05665e-02, 2.75870e-03]\n",
    "x_zprime1   = [1,2,3,3,4]\n",
    "\n",
    "th_zprime10 = [4.48526e+01, 2.26215e+00, 2.72788e-01, 5.15542e-02]\n",
    "x_zprime10  = [1,2,3,4]\n",
    "\n",
    "\n",
    "\n",
    "th_zprime30 = [1.29361e+02, 7.74166e+00, 1.17252e+00, 2.88839e-01]\n",
    "x_zprime30  = [1,2,3,4]\n",
    "\n",
    "\n",
    "th_zprimeDM = [-1, -1, -1, -1, -1, -1, -1, -1, -1] \n",
    "x_zprimeDM  = [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_zprimeDM = [2.222,\n",
    "0.387,\n",
    "0.09428,\n",
    "0.0279,\n",
    "0.009327,\n",
    "0.003507,\n",
    "0.001484,\n",
    "0.0007087,\n",
    "0.0003801,]\n",
    "\n",
    "ex_rsgluon = [21.03,\n",
    "3.656,\n",
    "0.9417,\n",
    "0.3039,\n",
    "0.1163,\n",
    "0.05138,\n",
    "0.02556,\n",
    "0.01422,\n",
    "0.008631,]\n",
    "\n",
    "\n",
    "ex_zprime10 = [0.3622,\n",
    "0.01895,\n",
    "0.002112,\n",
    "0.0003889,]\n",
    "\n",
    "ex_zprime30 = [0.1081,\n",
    "0.006689,\n",
    "0.0009523,\n",
    "0.0002273,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "zprimeDM_xs = {\n",
    "    '1000': 2.222,\n",
    "    '1500': 0.387,\n",
    "    '2000': 0.09428,\n",
    "    '2500': 0.0279,\n",
    "    '3000': 0.009327,\n",
    "    '3500': 0.003507,\n",
    "    '4000': 0.001484,\n",
    "    '4500': 0.0007087,\n",
    "    '5000': 0.0003801,\n",
    "}\n",
    "\n",
    "zprime10_xs = {\n",
    "    '1000': 0.3622,\n",
    "    '2000': 0.01895,\n",
    "    '3000': 0.002112,\n",
    "    '4000': 0.0003889,\n",
    "}\n",
    "\n",
    "zprime30_xs = {\n",
    "    '1000': 0.1081,\n",
    "    '2000': 0.006689,\n",
    "    '3000': 0.0009523,\n",
    "    '4000': 0.0002273,\n",
    "}\n",
    "\n",
    "rsgluon_xs = {\n",
    "    '1000': 21.03,\n",
    "    '1500': 3.656,\n",
    "    '2000': 0.9417,\n",
    "    '2500': 0.3039,\n",
    "    '3000': 0.1163,\n",
    "    '3500': 0.05138,\n",
    "    '4000': 0.02556,\n",
    "    '4500': 0.01422,\n",
    "    '5000': 0.008631,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(zprimeDM_xs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.103e+01, 9.417e-01, 3.039e-01, 1.422e-02, 5.138e-02, 1.163e-01,\n",
       "       8.631e-03, 3.656e+00, 2.556e-02])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([item for key, item in rsgluon_xs.items()])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    \n",
    "    'rsgluon': {\n",
    "        'theory' : th_rsgluon,\n",
    "        'expected': ex_rsgluon,\n",
    "        'mass': x_rsgluon,\n",
    "    },\n",
    "    \n",
    "    'zprime1': {\n",
    "        'theory' : th_zprime1,\n",
    "        'expected': [],\n",
    "        'mass': x_zprime1,\n",
    "    },\n",
    "        \n",
    "    'zprime10': {\n",
    "        'theory' : th_zprime10,\n",
    "        'expected': ex_zprime10,\n",
    "        'mass': x_zprime10,\n",
    "    },\n",
    "    \n",
    "    'zprime30': {\n",
    "        'theory' : th_zprime30,\n",
    "        'expected': ex_zprime30,\n",
    "        'mass': x_zprime30,\n",
    "    },\n",
    "    'zprimeDM': {\n",
    "        'theory' : th_zprimeDM,\n",
    "        'expected': ex_zprimeDM,\n",
    "        'mass': x_zprimeDM,\n",
    "    }\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"zprime30\": {\n",
      "        \"expected\": [\n",
      "            0.1081, \n",
      "            0.006689, \n",
      "            0.0009523, \n",
      "            0.0002273\n",
      "        ], \n",
      "        \"mass\": [\n",
      "            1, \n",
      "            2, \n",
      "            3, \n",
      "            4\n",
      "        ], \n",
      "        \"theory\": [\n",
      "            129.361, \n",
      "            7.74166, \n",
      "            1.17252, \n",
      "            0.288839\n",
      "        ]\n",
      "    }, \n",
      "    \"zprime1\": {\n",
      "        \"expected\": [], \n",
      "        \"mass\": [\n",
      "            1, \n",
      "            2, \n",
      "            3, \n",
      "            3, \n",
      "            4\n",
      "        ], \n",
      "        \"theory\": [\n",
      "            4.5054, \n",
      "            0.20551, \n",
      "            0.0205665, \n",
      "            0.0027587\n",
      "        ]\n",
      "    }, \n",
      "    \"zprime10\": {\n",
      "        \"expected\": [\n",
      "            0.3622, \n",
      "            0.01895, \n",
      "            0.002112, \n",
      "            0.0003889\n",
      "        ], \n",
      "        \"mass\": [\n",
      "            1, \n",
      "            2, \n",
      "            3, \n",
      "            4\n",
      "        ], \n",
      "        \"theory\": [\n",
      "            44.8526, \n",
      "            2.26215, \n",
      "            0.272788, \n",
      "            0.0515542\n",
      "        ]\n",
      "    }, \n",
      "    \"rsgluon\": {\n",
      "        \"expected\": [\n",
      "            21.03, \n",
      "            3.656, \n",
      "            0.9417, \n",
      "            0.3039, \n",
      "            0.1163, \n",
      "            0.05138, \n",
      "            0.02556, \n",
      "            0.01422, \n",
      "            0.008631\n",
      "        ], \n",
      "        \"mass\": [\n",
      "            1, \n",
      "            1.5, \n",
      "            2, \n",
      "            2.5, \n",
      "            3, \n",
      "            3.5, \n",
      "            4, \n",
      "            4.5, \n",
      "            5\n",
      "        ], \n",
      "        \"theory\": [\n",
      "            26.065, \n",
      "            4.5747, \n",
      "            1.23864, \n",
      "            0.40768, \n",
      "            0.16757, \n",
      "            0.07085, \n",
      "            0.036491, \n",
      "            0.020839, \n",
      "            0.0118235\n",
      "        ]\n",
      "    }, \n",
      "    \"zprimeDM\": {\n",
      "        \"expected\": [\n",
      "            2.222, \n",
      "            0.387, \n",
      "            0.09428, \n",
      "            0.0279, \n",
      "            0.009327, \n",
      "            0.003507, \n",
      "            0.001484, \n",
      "            0.0007087, \n",
      "            0.0003801\n",
      "        ], \n",
      "        \"mass\": [\n",
      "            1.0, \n",
      "            1.5, \n",
      "            2.0, \n",
      "            2.5, \n",
      "            3.0, \n",
      "            3.5, \n",
      "            4.0, \n",
      "            4.5, \n",
      "            5.0\n",
      "        ], \n",
      "        \"theory\": [\n",
      "            -1, \n",
      "            -1, \n",
      "            -1, \n",
      "            -1, \n",
      "            -1, \n",
      "            -1, \n",
      "            -1, \n",
      "            -1, \n",
      "            -1\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(data, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('signal_xs.json', 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ùëç‚Ä≤‚Üíùë°ùë°¬Ø  Background Estimation\n",
    "Adapted from background estimation for the 2023 CMSDAS $b^\\ast \\to tW$ exercise, using the updated version of 2DAlphabet\n",
    "\n",
    "## Getting started (in bash shell)\n",
    "\n",
    "First, ensure that you have [SSH keys tied to your github account](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent) and that they've been added to the ssh-agent:\n",
    "```\n",
    "eval \"$(ssh-agent -s)\"\n",
    "ssh-add ~/.ssh/id_xyz\n",
    "```\n",
    "This step is necessary for cloning some of the Combine tools used in the 2DAlphabet installation.\n",
    "\n",
    "### Setup CMSSW and 2DAlphabet environment:\n",
    "Assuming you've already created the `~/public/CMSDAS2023/` directory, first create the CMSSW environment:\n",
    "```\n",
    "ssh -XY USERNAME@lxplus.cern.ch\n",
    "export SCRAM_ARCH=slc7_amd64_gcc700\n",
    "cd public/CMSDAS2023/\n",
    "cmsrel CMSSW_10_6_14\n",
    "cd CMSSW_10_6_14/src\n",
    "cmsenv\n",
    "```\n",
    "\n",
    "Now set up 2DAlphabet:\n",
    "```\n",
    "cd ~/public/CMSDAS2023/CMSSW_10_6_14/src/\n",
    "git clone https://github.com/mdmorris/2DAlphabet.git\n",
    "git clone --branch 102x https://github.com/cms-analysis/HiggsAnalysis-CombinedLimit.git HiggsAnalysis/CombinedLimit\n",
    "curl -s https://raw.githubusercontent.com/lcorcodilos/CombineHarvester/master/CombineTools/scripts/sparse-checkout-ssh.sh | bash\n",
    "scram b clean; scram b -j 4\n",
    "cmsenv\n",
    "```\n",
    "\n",
    "Now, create a virtual environment in which to install 2DAlphabet:\n",
    "```\n",
    "python -m virtualenv twoD-env\n",
    "source twoD-env/bin/activate\n",
    "cd 2DAlphabet\n",
    "python setup.py develop\n",
    "```\n",
    "\n",
    "Then, check that the 2DAlphabet installation worked by opening a python shell:\n",
    "```\n",
    "python\n",
    "```\n",
    "then, inside the python shell:\n",
    "```\n",
    "import ROOT\n",
    "r = ROOT.RooParametricHist()\n",
    "```\n",
    "\n",
    "### Finally, clone this repo to the `src` directory as well:\n",
    "```\n",
    "cd ~/public/CMSDAS2023/CMSSW_10_6_14/src/\n",
    "git clone https://github.com/mdmorris/BstarToTW_CMSDAS2023_BackgroundEstimation.git\n",
    "```\n",
    "OR fork the code onto your own personal space and set the upstream:\n",
    "```\n",
    "https://github.com/<USERNAME>/BstarToTW_CMSDAS2023_BackgroundEstimation.git\n",
    "cd BstarToTW_CMSDAS2023_BackgroundEstimation\n",
    "git remote add upstream https://github.com/mdmorris/BstarToTW_CMSDAS2023_BackgroundEstimation.git\n",
    "git remote -v\n",
    "```\n",
    "\n",
    "## What to do after reconnecting to LXPLUS:\n",
    "Go back to the directory where you installed 2DAlphabet and where the virtual environment resides:\n",
    "```\n",
    "ssh -XY USERNAME@lxplus.cern.ch\n",
    "cd ~/public/CMSDAS2023/CMSSW_10_6_14/src/\n",
    "cmsenv\n",
    "source twoD-env/bin/activate\n",
    "```\n",
    "Then you should be good to go!\n",
    "\n",
    "## Background estimate\n",
    "For this exercise we will use the [`2DAlphabet`](https://github.com/mdmorris/2DAlphabet) github package. This package uses `.json` configuration files to specify the input histograms (to perform the fit) and the uncertainties. These uncertainties will be used inside of the `Higgs Combine` backend, the fitting package used widely within CMS. The 2DAlphabet package serves as a nice interface with Combine to allow the user to use the 2DAlphabet method without having to create their own custom version of combine. \n",
    "\n",
    "# Input root files\n",
    "\n",
    "Root files with the pass and fail histograms can be found in:\n",
    "\n",
    "`/afs/cern.ch/user/m/mmorris/public/ttbarAllHad/twodalphabet/`\n",
    "\n",
    "# Configuration file\n",
    "\n",
    "The configuration file that you will be using is called `bstar.json`, located in this repository. Let's take a look at this file and see the various parts:\n",
    "\n",
    "* `GLOBAL`\n",
    "  - This section contains meta information regarding the location (`path`), filenames (`FILE`), and input histogram names (`HIST`) for all ROOT files used in the background estimation procedure.\n",
    "  - Everything in this section will be used in a file-wide find-and-replace. So wherever you see the name of the sub-objects in this file, it will be expanded by the value assigned to it in this section. \n",
    "  - Additionally, the `SIGNAME` list should include the name(s) of all signals you wish to investigate, so that they are added to the workspace when you run the python script.\n",
    "    - If you wanted to investigate limits for only three signals, for example, you'd just add their names as given in the ROOT files to this list. \n",
    "    - For this exercise, the default is `signalLH2400`, the 2.4 TeV signal sample. You'll want to change this as the exercise progresses\n",
    "\n",
    "* `REGIONS`\n",
    "  - This section contains the various regions we are interested in transferring between.\n",
    "  - Each region contains a `PROCESSES` object, listing the signals and backgrounds to be included in the fit, as well as  `BINNING` object, which is defined elsewhere in the config file.\n",
    "  - The name of each region in `REGIONS` is dependent on the input histogram name, as well as your choice of `HIST` name in the `GLOBAL` section above\n",
    "    - For instance, in this file we declared `HIST = MtwvMt$region`, where `$region` will be expanded as the name given in `REGIONS`. \n",
    "    - We chose this name because the input histograms are titled `MtwvMtPass` and `MtwvMtFail` for the Pass and Fail regions, respectively. \n",
    "\n",
    "* `PROCESSES`\n",
    "  - In this section we define all of the various process ROOT files that will be used to produce the fit. These include data, signals, and backgrounds.\n",
    "  - Each process contains its own set of options:\n",
    "    - `SYSTEMATICS`: a list of systematic uncertainties, whose properties are defined elsewhere in the config file\n",
    "    - `SCALE`: how much to scale this process by in the fit\n",
    "    - `COLOR`: color to plot in the fit (ROOT color schema)\n",
    "    - `TYPE`: `DATA`, `BKG`, `SIGNAL`\n",
    "    - `TITLE`: label in the plot legend (LaTeX compatible)\n",
    "    - `ALIAS`: if the process has a different filename than standard, this will be what replaces `process` in the \n",
    "`GLOBAL` section's `FILE` option, so that this process gets picked up properly\n",
    "    - `LOC`: the location of the file, using the definitions laid out in `GLOBAL`\n",
    "\n",
    "* `SYSTEMATICS`\n",
    "  - This contains the names of all systematic uncertainties you want to apply to the various processes.\n",
    "  - The `CODE` key describes the type of systematic that will be used in Combine.\n",
    "  - The `VAL` key is how we assign the value of that uncertainty. For instance, a `VAL` of `1.018` in the `lumi` (luminosity) means that this systematic has a 1.8\\% uncertainty on the yield.\n",
    "\n",
    "* `BINNING`\n",
    "  - This section allows us to name and define custom binning schema. After naming the schema, one would define several variables for both `X` and `Y`:\n",
    "    - `NAME`: allows us to denote what is being plotted on the given axis\n",
    "    - `TITLE`: the axis label for the plot (LaTeX enabled)\n",
    "    - `BINS`: a list of bins\n",
    "    - `SIGSTART`, `SIGEND`: the bins defining a window `[SIGSTART, SIGEND]` around which to blind (if the blinded option is selected)\n",
    "\n",
    "* `OPTIONS`\n",
    "  - A list of boolean and other options to be considered when generating the fit\n",
    "  - (explanation WIP)\n",
    "\n",
    "# Running the ML fit\n",
    "By default, the `ttbar.py` python API should set up a workspace, perform the ML fit, and plot the distributions. \n",
    "\n",
    "```\n",
    "python ttbar.py\n",
    "```\n",
    "\n",
    "The output is stored in the `ttbarfits/` output directory by default.\n",
    "\n",
    "# Running the ML fit for b-tag and y analysis regions\n",
    "\n",
    "run the `python ttbar.py` command for all 6 regions:\n",
    "\n",
    "```\n",
    "cd regions/2016\n",
    "python ttbar.py cen0b\n",
    "python ttbar.py cen1b\n",
    "python ttbar.py cenbb\n",
    "python ttbar.py fwd0b\n",
    "python ttbar.py fwd1b\n",
    "python ttbar.py fwd2b\n",
    "\n",
    "```\n",
    "\n",
    "This will create separate directories labelled by the region and function, for example \n",
    "\n",
    "```\n",
    "ttbarfits_cen0b_3x1\n",
    "```\n",
    "\n",
    "In the ttbarfits directory, data cards are saved in the signal{XXXXX} directories. In order to combine the data cards from all 6 regions into one inclusive data card, run (still in the `regions/2016` directory)\n",
    "\n",
    "```\n",
    "./combine_cards.sh\n",
    "```\n",
    "\n",
    "The combineTool.py jobsa are submitted to condor, and when the jobs are completed the combined data cards and asysmptotic root files can be found in the new directory `regions/2016/ttbarfits_inclusive`\n",
    "\n",
    "In order to plot the limit, run the `limits.ipynb` notebook.\n",
    "\n",
    "Repeat these steps for 2017 and 2018 in `regions/2017` and `regions/2018`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The json files for the inclusive histograms are located in `inclusive/`\n",
    "The json files for the split b-tag and y regions are locateed in `regions/2016`, `regions/2017`, and `regions/2018`\n",
    "\n",
    "# Systematics\n",
    "Systematic uncertainties were described in the config file section above. Add the Top pT uncertainties to the appropriate processes in the config file, then re-run the fit after having copied the old Combine card somewhere safe. Compare the pre- and post-Top pT Combine cards using `diff`.\n",
    "\n",
    "# Limit setting\n",
    "\n",
    "Limits for each signal are calculated using the `perform_limit` function in `ttbar.py`. The limits can then be plotted using the `set_limits.py` script, or interactively with the `limits.ipynb` notebook. The mass points and cross sections for each signal are located in `signal_xs.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 800, 1100, 1400, 1700, 2000, 2300, 2600, 2900, 3200, 3500, 3800,\n",
       "       4100, 4400, 4700, 5000, 5300, 5600, 5900, 6200, 6500])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(800,6800,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 800., 1100., 1400., 1700., 2000., 2300., 2600., 2900., 3200.,\n",
       "       3500., 3800., 4100., 4400., 4700., 5000., 5300., 5600., 5900.,\n",
       "       6200., 6500.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(800,6500,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signals = os.listdir('regions/2016/ttbarfits_inclusive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(697, 'signalRSGluon1000_area')\n",
      "(697, 'signalRSGluon1500_area')\n",
      "(1014420, 'signalRSGluon2000_area')\n",
      "(697, 'signalRSGluon2500_area')\n",
      "(697, 'signalRSGluon3000_area')\n",
      "(697, 'signalRSGluon3500_area')\n",
      "(697, 'signalRSGluon4000_area')\n",
      "(697, 'signalRSGluon4500_area')\n",
      "(697, 'signalRSGluon5000_area')\n",
      "(5846, 'signalRSGluon5500_area')\n",
      "(5846, 'signalRSGluon6000_area')\n",
      "(697, 'signalZPrime1000_10_area')\n",
      "(697, 'signalZPrime1000_1_area')\n",
      "(697, 'signalZPrime1000_30_area')\n",
      "(697, 'signalZPrime1000_DM_area')\n",
      "(5846, 'signalZPrime1200_10_area')\n",
      "(697, 'signalZPrime1200_1_area')\n",
      "(5846, 'signalZPrime1200_30_area')\n",
      "(5846, 'signalZPrime1400_10_area')\n",
      "(697, 'signalZPrime1400_1_area')\n",
      "(5846, 'signalZPrime1400_30_area')\n",
      "(697, 'signalZPrime1500_DM_area')\n",
      "(697, 'signalZPrime1600_1_area')\n",
      "(5846, 'signalZPrime1800_10_area')\n",
      "(697, 'signalZPrime1800_1_area')\n",
      "(5846, 'signalZPrime1800_30_area')\n",
      "(697, 'signalZPrime2000_10_area')\n",
      "(697, 'signalZPrime2000_1_area')\n",
      "(697, 'signalZPrime2000_30_area')\n",
      "(697, 'signalZPrime2000_DM_area')\n",
      "(5846, 'signalZPrime2500_10_area')\n",
      "(697, 'signalZPrime2500_1_area')\n",
      "(5846, 'signalZPrime2500_30_area')\n",
      "(697, 'signalZPrime2500_DM_area')\n",
      "(697, 'signalZPrime3000_10_area')\n",
      "(697, 'signalZPrime3000_1_area')\n",
      "(697, 'signalZPrime3000_30_area')\n",
      "(697, 'signalZPrime3000_DM_area')\n",
      "(5846, 'signalZPrime3500_10_area')\n",
      "(697, 'signalZPrime3500_1_area')\n",
      "(5846, 'signalZPrime3500_30_area')\n",
      "(697, 'signalZPrime3500_DM_area')\n",
      "(697, 'signalZPrime4000_10_area')\n",
      "(697, 'signalZPrime4000_1_area')\n",
      "(697, 'signalZPrime4000_30_area')\n",
      "(697, 'signalZPrime4000_DM_area')\n",
      "(5846, 'signalZPrime4500_10_area')\n",
      "(697, 'signalZPrime4500_1_area')\n",
      "(5846, 'signalZPrime4500_30_area')\n",
      "(697, 'signalZPrime4500_DM_area')\n",
      "(5846, 'signalZPrime5000_10_area')\n",
      "(5846, 'signalZPrime5000_30_area')\n",
      "(697, 'signalZPrime5000_DM_area')\n",
      "(5846, 'signalZPrime6000_10_area')\n",
      "(5846, 'signalZPrime6000_30_area')\n",
      "(5846, 'signalZPrime7000_10_area')\n",
      "(5846, 'signalZPrime7000_30_area')\n"
     ]
    }
   ],
   "source": [
    "for signal in signals:\n",
    "    if 'area' in signal:\n",
    "        path = 'regions/2016/ttbarfits_inclusive/'+signal+'/higgsCombine.Test.AsymptoticLimits.mH120.root'\n",
    "        if os.path.exists(path):\n",
    "            print(os.path.getsize(path), signal)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
